# D3QN 架构图完整指南

## 📊 D3QN 架构总体流程图

```
╔════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗
║                                    D3QN 架构图（无 Batch 维度）                                              ║
╚════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝


                                          ┌─────────────────────┐
                                          │   Environment       │
                                          │   (城市调度)        │
                                          └──────────┬──────────┘
                                                     │
                                                     ↓
                          ┌──────────────────────────────────────────────────────┐
                          │                                                      │
                          │              INPUT STATE (400×5)                     │
                          │                                                      │
                          │  ┌─────────────────────────────────────────────┐    │
                          │  │ 400 个网格的特征向量：                       │    │
                          │  │ • 订单数量 (Orders)                        │    │
                          │  │ • 空闲车辆 (Idle Vehicles)                 │    │
                          │  │ • 繁忙车辆 (Busy Vehicles)                 │    │
                          │  │ • 时间特征 sin(t)                          │    │
                          │  │ • 时间特征 cos(t)                          │    │
                          │  └─────────────────────────────────────────────┘    │
                          │                                                      │
                          │               维度: 400 × 5                         │
                          │               高度: 100px  宽度: 80px              │
                          │                                                      │
                          └──────────────────┬───────────────────────────────────┘
                                             │
                                             ↓
        ┌────────────────────────────────────────────────────────────────────────────────────────┐
        │                                                                                        │
        │                        MGCN 多图卷积网络处理                                          │
        │                                                                                        │
        │  ┌─────────────────────────────────┐        ┌─────────────────────────────────┐     │
        │  │   邻接图分支                      │        │   POI 图分支                    │     │
        │  │   (Adjacency Graph)             │        │   (POI Graph)                   │     │
        │  │                                 │        │                                 │     │
        │  │  输入: 400×5                    │        │  输入: 400×5                    │     │
        │  │    ↓                            │        │    ↓                            │     │
        │  │  GCN Layer 1                    │        │  GCN Layer 1                    │     │
        │  │  (5 → 64)                       │        │  (5 → 64)                       │     │
        │  │  输出: 400×64                   │        │  输出: 400×64                   │     │
        │  │  高度: 220px                    │        │  高度: 220px                    │     │
        │  │    ↓                            │        │    ↓                            │     │
        │  │  GCN Layer 2                    │        │  GCN Layer 2                    │     │
        │  │  (64 → 32)                      │        │  (64 → 32)                      │     │
        │  │  输出: 400×32                   │        │  输出: 400×32                   │     │
        │  │  高度: 160px                    │        │  高度: 160px                    │     │
        │  │                                 │        │                                 │     │
        │  └─────────────────────────────────┘        └─────────────────────────────────┘     │
        │           ↓                                           ↓                              │
        │           └───────────────────┬────────────────────────┘                            │
        │                               ↓                                                     │
        │                   ┌───────────────────────┐                                         │
        │                   │  Attention Fusion     │                                         │
        │                   │  (注意力融合)         │                                         │
        │                   │  400×32 + 400×32     │                                         │
        │                   │    ↓                 │                                         │
        │                   │  输出: 400×32        │                                         │
        │                   │  高度: 160px         │                                         │
        │                   └───────────────────────┘                                         │
        │                                                                                     │
        └─────────────────────────────────┬──────────────────────────────────────────────────┘
                                          │
                                          ↓
                          ┌──────────────────────────────────────────────────────┐
                          │                                                      │
                          │          全局池化 (Global Pooling)                   │
                          │                                                      │
                          │  400 个网格 → 1 个全局特征向量                       │
                          │  输入: 400×32                                        │
                          │    ↓                                                 │
                          │  平均池化或注意力池化                                │
                          │    ↓                                                 │
                          │  输出: 32                                            │
                          │  高度: 160px  宽度: 70px                             │
                          │                                                      │
                          └──────────────────┬───────────────────────────────────┘
                                             │
                                             ↓
                          ┌──────────────────────────────────────────────────────┐
                          │                                                      │
                          │          特征融合层 (Feature Fusion)                 │
                          │                                                      │
                          │  全局特征 (32)                                       │
                          │  + 位置编码 (16)                                     │
                          │  + 日期编码 (8)                                      │
                          │  = 56 维                                             │
                          │    ↓                                                 │
                          │  融合网络 MLP                                        │
                          │  56 → 128 → 64                                       │
                          │    ↓                                                 │
                          │  输出: 64                                            │
                          │  高度: 220px  宽度: 80px                             │
                          │                                                      │
                          └──────────────────┬───────────────────────────────────┘
                                             │
                                             ↓
        ┌────────────────────────────────────────────────────────────────────────────────────────┐
        │                                                                                        │
        │                        Dueling DQN 头 (Dueling DQN Head)                             │
        │                                                                                        │
        │                    输入: 64 维融合特征向量                                            │
        │                                                                                        │
        │  ┌──────────────────────────────────┐        ┌──────────────────────────────────┐   │
        │  │   Value Stream (价值流)           │        │   Advantage Stream (优势流)      │   │
        │  │                                  │        │                                  │   │
        │  │  64 → 128 (MLP Layer 1)          │        │  64 → 128 (MLP Layer 1)          │   │
        │  │  高度: 290px  宽度: 60px         │        │  高度: 290px  宽度: 60px         │   │
        │  │    ↓                             │        │    ↓                             │   │
        │  │  128 → 1 (Output Layer)          │        │  128 → 179 (Output Layer)        │   │
        │  │  高度: 80px   宽度: 60px         │        │  高度: 350px  宽度: 60px         │   │
        │  │                                  │        │                                  │   │
        │  │  输出: V(s)                      │        │  输出: A(s,a)                    │   │
        │  │  (状态价值函数)                   │        │  (动作优势函数)                   │   │
        │  │                                  │        │                                  │   │
        │  └──────────────────────────────────┘        └──────────────────────────────────┘   │
        │           ↓                                           ↓                              │
        │           └───────────────────┬────────────────────────┘                            │
        │                               ↓                                                     │
        │                   ┌───────────────────────────────┐                                 │
        │                   │   Q 值聚合 (Aggregation)      │                                 │
        │                   │                               │                                 │
        │                   │  Q(s,a) = V(s) +             │                                 │
        │                   │            [A(s,a)           │                                 │
        │                   │             - mean(A(s,·))]  │                                 │
        │                   │                               │                                 │
        │                   │  输出: 179 维 Q 值向量        │                                 │
        │                   │  高度: 350px  宽度: 80px      │                                 │
        │                   └───────────────┬───────────────┘                                 │
        │                                   │                                                 │
        │                                   ↓                                                 │
        │                         ┌──────────────────┐                                        │
        │                         │  Q 值输出        │                                        │
        │                         │  (179×1)         │                                        │
        │                         │  179 个热点      │                                        │
        │                         │  的 Q 值         │                                        │
        │                         └──────────────────┘                                        │
        │                                                                                     │
        └─────────────────────────────────┬──────────────────────────────────────────────────┘
                                          │
                                          ↓
                          ┌──────────────────────────────────────────────────────┐
                          │                                                      │
                          │              策略 (Policy)                           │
                          │                                                      │
                          │  所有 179 个热点的 Q 值                              │
                          │  Q = [Q₁, Q₂, Q₃, ..., Q₁₇₉]                       │
                          │                                                      │
                          └──────────────────┬───────────────────────────────────┘
                                             │
                                             ↓
                          ┌──────────────────────────────────────────────────────┐
                          │                                                      │
                          │              智能体决策 (Agent)                      │
                          │                                                      │
                          │  ε-贪心策略:                                         │
                          │  • 概率 ε: 随机选择一个热点                         │
                          │  • 概率 1-ε: 选择 Q 值最大的热点                    │
                          │                                                      │
                          │  a* = argmax Q(s,a)                                 │
                          │                                                      │
                          └──────────────────┬───────────────────────────────────┘
                                             │
                                             ↓
                          ┌──────────────────────────────────────────────────────┐
                          │                                                      │
                          │              动作 (Action)                           │
                          │                                                      │
                          │  选择的热点位置 (0-178 中的一个)                     │
                          │                                                      │
                          └──────────────────┬───────────────────────────────────┘
                                             │
                                             ↓
                          ┌──────────────────────────────────────────────────────┐
                          │                                                      │
                          │              执行动作，获得奖励                       │
                          │                                                      │
                          │  • 下一状态 s'                                       │
                          │  • 奖励 r (多阶段奖励)                               │
                          │  • 是否完成 done                                     │
                          │                                                      │
                          └──────────────────┬───────────────────────────────────┘
                                             │
                                             ↓
                          ┌──────────────────────────────────────────────────────┐
                          │                                                      │
                          │          目标网络 (Target Network)                   │
                          │          (结构完全相同的 D3QN)                      │
                          │                                                      │
                          │  • 参数定期从 Q 网络复制                             │
                          │  • 用于计算目标 Q 值                                 │
                          │  • 提高训练稳定性                                    │
                          │                                                      │
                          │  Q_target = r + γ × max Q'(s', a')                 │
                          │                                                      │
                          └──────────────────┬───────────────────────────────────┘
                                             │
                                             ↓
                          ┌──────────────────────────────────────────────────────┐
                          │                                                      │
                          │              计算损失和反向传播                       │
                          │                                                      │
                          │  Loss = (Q(s,a) - Q_target)²                        │
                          │                                                      │
                          │  更新 Q 网络参数                                     │
                          │                                                      │
                          └──────────────────────────────────────────────────────┘
```

---

## 📏 PPT 长方体尺寸参考表

### 记忆方法：以输入层 (5维) 为基准 = 100px 高

| 维度 | 倍数 | 高度 | 宽度 | 说明 |
|---|---|---|---|---|
| **5** | 1.0x | **100px** | **80px** | 输入层，基准 |
| **32** | 2.0x | **160px** | **80px** | MGCN 输出，池化后 |
| **64** | 2.8x | **220px** | **80px** | GCN 第1层，融合后 |
| **128** | 3.8x | **290px** | **60px** | Dueling 隐藏层 |
| **179** | 4.5x | **350px** | **60px** | Advantage 输出，最大 |

### 3D 长方体的三个面

对于每个长方体，需要画三个面：

#### 正面（矩形）
- 宽度 = 上表中的 "宽度"
- 高度 = 上表中的 "高度"
- 颜色：浅色（如浅蓝 RGB(100, 150, 255)）

#### 右侧面（平行四边形）
- 宽度 = 正面宽度的 30%
- 高度 = 正面高度
- 旋转角度 = 30-45 度
- 颜色：深色（如深蓝 RGB(50, 100, 200)）

#### 顶面（平行四边形）
- 宽度 = 正面宽度
- 高度 = 正面高度的 25%
- 旋转角度 = 30-45 度
- 颜色：最浅色（如浅灰蓝 RGB(150, 180, 255)）

---

## 🎨 配色方案

| 部分 | RGB 颜色 | 含义 |
|---|---|---|
| 输入层 | (100, 150, 255) | 浅蓝 - 原始输入 |
| GCN 处理 | (230, 140, 50) | 橙色 - 卷积处理 |
| POI 分支 | (150, 200, 150) | 浅绿 - 另一个分支 |
| 融合层 | (180, 180, 180) | 灰色 - 信息融合 |
| 全局池化 | (200, 150, 200) | 紫色 - 汇聚操作 |
| 上下文融合 | (150, 200, 255) | 浅青 - 加入背景 |
| Value 分支 | (100, 150, 100) | 深绿 - 价值函数 |
| Advantage 分支 | (150, 100, 100) | 深红 - 优势函数 |
| 最终输出 | (255, 200, 100) | 金黄 - Q 值输出 |

---

## 📐 维度变化总结

| 阶段 | 输入维度 | 输出维度 | 说明 |
|---|---|---|---|
| **输入** | - | 400×5 | 400 个网格，5 个特征 |
| **MGCN 第1层** | 400×5 | 400×64 | 特征维度扩展 |
| **MGCN 第2层** | 400×64 | 400×32 | 特征维度压缩 |
| **全局池化** | 400×32 | 32 | 网格数量从 400 → 1 |
| **特征融合** | 32+16+8 | 64 | 加入位置和时间信息 |
| **Value Stream** | 64 | 1 | 状态价值 |
| **Advantage Stream** | 64 | 179 | 动作优势 |
| **Q 值聚合** | 1+179 | 179 | 最终 Q 值 |

---

## 🔑 核心概念说明

### 【MGCN - 多图卷积网络】
- **邻接图分支**：捕捉地理位置的相邻关系
- **POI 图分支**：捕捉功能相似性（如都是商业区）
- **注意力融合**：自动学习两个分支的权重
- **输出**：每个网格的 32 维特征向量

### 【全局池化】
- 将 400 个网格的特征汇聚成 1 个全局特征
- 从"网格级别"转变为"全局决策级别"
- 使用平均池化或注意力池化

### 【特征融合】
- 全局特征 (32) + 位置编码 (16) + 日期编码 (8) = 56 维
- 通过 MLP 融合成 64 维向量
- 包含了地理信息、时间信息和全局状态信息

### 【Dueling DQN 头】
- **Value Stream (V(s))**：评估"这个状态有多好"（与动作无关）
- **Advantage Stream (A(s,a))**：评估"这个动作相对于其他动作有多好"（与状态无关）
- **Q(s,a) = V(s) + [A(s,a) - mean(A(s,·))]**
- **优势**：分离价值和优势，学习更稳定，收敛更快

### 【Double DQN】
- **Current Network**：用于选择动作和评估 Q 值
- **Target Network**：用于计算目标 Q 值，减少过度估计
- **定期复制参数**：每 N 步将 Q 网络参数复制到目标网络

### 【D3QN = Dueling + Double + Deep】
- **Deep**：使用深度神经网络（MGCN + MLP）
- **Double**：使用两个网络减少过度估计
- **Dueling**：分离价值和优势函数提高稳定性

---

## 📋 PPT 绘制步骤清单

- [ ] 步骤 1：新建幻灯片，设置为横向 16:9
- [ ] 步骤 2：启用网格（View → Grid and Guides）
- [ ] 步骤 3：添加标题 "Dueling DQN Architecture (D3QN)"
- [ ] 步骤 4：绘制输入层 (400×5) - 100px 高
- [ ] 步骤 5：绘制 MGCN 邻接图分支
  - [ ] GCN Layer 1 (400×64) - 220px 高
  - [ ] GCN Layer 2 (400×32) - 160px 高
- [ ] 步骤 6：绘制 MGCN POI 图分支（相同结构，不同颜色）
- [ ] 步骤 7：绘制融合操作（注意力融合）
- [ ] 步骤 8：绘制全局池化（400×32 → 32）
- [ ] 步骤 9：绘制特征融合层 (64)
- [ ] 步骤 10：绘制 Value Stream
  - [ ] 隐藏层 (128) - 290px 高
  - [ ] 输出层 (1) - 80px 高
- [ ] 步骤 11：绘制 Advantage Stream
  - [ ] 隐藏层 (128) - 290px 高
  - [ ] 输出层 (179) - 350px 高
- [ ] 步骤 12：绘制 Q 值聚合操作
- [ ] 步骤 13：添加箭头连接各层
- [ ] 步骤 14：添加维度标注
- [ ] 步骤 15：添加虚线框组织模块
- [ ] 步骤 16：美化（阴影、透明度、对齐）

---

## 💡 关键提示

1. **不显示 Batch 维度**：架构图只显示单个样本的数据流，更清晰
2. **高度与维度成正比**：使用 `高度 = 60 + √维度 × 20` 的公式
3. **三个面的立体效果**：正面 + 右侧面 + 顶面 = 3D 长方体
4. **颜色区分不同功能**：蓝色输入、橙色处理、绿色价值、红色优势
5. **虚线框组织模块**：用虚线框将相关的长方体组织在一起

---

## 📝 参考对比

### 参考图的结构
```
Environment → State → Current Network → Q(s) → Policy → Agent → Action
                           ↓
                      Target Network
```

### 你的 D3QN 对应
```
Environment → State (400×5) → D3QN Network (MGCN + Dueling) → Q(s,a) (179) → Policy → Agent → Action
                                          ↓
                                   Target Network (D3QN)
```

### 关键修改点
- 输入：17×1 → 400×5
- 中间层：64 → 400×32 (MGCN) → 64 (融合)
- 输出：16×1 → 179×1
- 架构：单一网络 → MGCN + Dueling 分支

---

## 🎯 现在你可以开始画了！

按照上面的步骤和尺寸参考表，在 PowerPoint 中一步一步绘制。有任何问题随时参考这个文档。祝你画图顺利！🚀

