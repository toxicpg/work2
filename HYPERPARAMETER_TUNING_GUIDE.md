# 超参数调整快速参考

## 核心奖励权重

| 参数 | 默认值 | 范围 | 调整方向 | 效果 |
|------|--------|------|---------|------|
| `W_MATCH` | 1.2 | 0.5-2.0 | ↑ 增大 | 强调快速匹配，提高匹配率 |
| `W_COMPLETION` | 2.0 | 1.0-3.0 | ↑ 增大 | 强调订单完成，提高完成率 |
| `W_WAIT_SCORE` | 0.4 | 0.1-1.0 | ↑ 增大 | 奖励短等待时间 |
| `W_WAIT` | 1.8 | 1.0-3.0 | ↑ 增大 | 惩罚长等待时间 |
| `W_CANCEL` | 1.0 | 0.5-2.0 | ↑ 增大 | 严厉惩罚取消订单 |
| `W_MATCH_SPEED` | 0.5 | 0.1-1.0 | ↑ 增大 | 强调匹配速度 |

## 时间常数

| 参数 | 默认值 | 范围 | 调整方向 | 效果 |
|------|--------|------|---------|------|
| `T_CHARACTERISTIC` | 240s | 120-600s | ↓ 减小 | 加强对长等待的惩罚 |
| `MAX_WAITING_TIME` | 300s | 180-600s | ↓ 减小 | 更严格的超时限制 |

## 探索参数

| 参数 | 默认值 | 范围 | 调整方向 | 效果 |
|------|--------|------|---------|------|
| `EPSILON_START` | 0.6 | 0.3-0.9 | ↑ 增大 | 初期探索更充分 |
| `EPSILON_END` | 0.1 | 0.01-0.2 | ↑ 增大 | 保留更多探索 |
| `EPSILON_DECAY` | 0.85 | 0.7-0.95 | ↑ 增大 | 探索衰减更缓慢 |

## 训练参数

| 参数 | 默认值 | 范围 | 调整方向 | 效果 |
|------|--------|------|---------|------|
| `LEARNING_RATE` | 1e-4 | 1e-5-1e-3 | ↑ 增大 | 学习更快但可能不稳定 |
| `BATCH_SIZE` | 256 | 64-512 | ↑ 增大 | 训练更稳定但内存占用增加 |
| `GAMMA` | 0.99 | 0.9-0.99 | ↓ 减小 | 更关注近期奖励 |

---

## 常见调整场景

### 场景 1: 完成率低 (< 80%)

**问题诊断**:
- 订单匹配不足
- 调度策略不合理

**调整方案**:
```python
REWARD_WEIGHTS = {
    'W_MATCH': 1.5,        # ↑ 从 1.2 增加到 1.5
    'W_COMPLETION': 2.5,   # ↑ 从 2.0 增加到 2.5
    'W_MATCH_SPEED': 0.7,  # ↑ 从 0.5 增加到 0.7
}
```

**预期效果**: 完成率应在 5-10 个 Episode 内提升到 85%+

---

### 场景 2: 等待时间长 (> 200s)

**问题诊断**:
- 匹配速度慢
- 接驾时间长

**调整方案**:
```python
REWARD_WEIGHTS = {
    'W_WAIT_SCORE': 0.8,   # ↑ 从 0.4 增加到 0.8
    'W_WAIT': 2.5,         # ↑ 从 1.8 增加到 2.5
}
REWARD_FORMULA_V4 = {
    'T_CHARACTERISTIC': 180  # ↓ 从 240 减小到 180
}
```

**预期效果**: 等待时间应在 10-20 个 Episode 内下降 20-30%

---

### 场景 3: 取消率高 (> 15%)

**问题诊断**:
- 调度覆盖不足
- 匹配能力不强

**调整方案**:
```python
REWARD_WEIGHTS = {
    'W_CANCEL': 2.0,       # ↑ 从 1.0 增加到 2.0
    'W_MATCH': 1.5,        # ↑ 从 1.2 增加到 1.5
}
CONFIG.MAX_WAITING_TIME = 250  # ↓ 从 300 减小到 250
```

**预期效果**: 取消率应在 5-10 个 Episode 内下降到 < 10%

---

### 场景 4: 模型不收敛 (Loss 不下降)

**问题诊断**:
- 学习率过高
- 奖励信号不稳定
- 探索不足

**调整方案**:
```python
LEARNING_RATE = 5e-5      # ↓ 从 1e-4 减小到 5e-5
EPSILON_DECAY = 0.90      # ↑ 从 0.85 增加到 0.90
EPSILON_START = 0.7       # ↑ 从 0.6 增加到 0.7
BATCH_SIZE = 512          # ↑ 从 256 增加到 512
```

**预期效果**: Loss 应在 10-20 个 Episode 内开始下降

---

### 场景 5: 模型过拟合 (Reward 波动大)

**问题诊断**:
- 探索不足
- 学习率过高
- 过度拟合训练数据

**调整方案**:
```python
EPSILON_START = 0.8       # ↑ 从 0.6 增加到 0.8
EPSILON_DECAY = 0.92      # ↑ 从 0.85 增加到 0.92
LEARNING_RATE = 5e-5      # ↓ 从 1e-4 减小到 5e-5
WEIGHT_DECAY = 1e-4       # ↑ 从 1e-5 增加到 1e-4
```

**预期效果**: Reward 曲线应变得更平滑，波动减少

---

## 调整步骤

### Step 1: 诊断问题
1. 运行 `python plot_training_curves.py` 查看曲线
2. 识别哪个指标偏离目标
3. 参考"常见调整场景"找到对应问题

### Step 2: 制定调整方案
1. 选择需要调整的参数（通常一次只调 1-2 个）
2. 参考上表中的"调整方向"
3. 在允许范围内进行调整

### Step 3: 验证效果
1. 修改 `config.py` 中的参数
2. 重新训练 3-5 个 Episode
3. 绘制曲线查看是否改进

### Step 4: 迭代优化
1. 如果改进，继续微调该参数
2. 如果无改进，尝试其他参数
3. 不要同时调整过多参数

---

## 调整优先级

### 🔴 高优先级 (直接影响主要目标)
1. `W_MATCH` - 影响匹配率
2. `W_WAIT_SCORE` / `W_WAIT` - 影响等待时间
3. `T_CHARACTERISTIC` - 影响等待时间评分

### 🟡 中优先级 (间接影响)
4. `W_COMPLETION` - 影响完成率
5. `W_CANCEL` - 影响取消率
6. `EPSILON_DECAY` - 影响探索与利用平衡

### 🟢 低优先级 (微调)
7. `W_MATCH_SPEED` - 微调匹配速度奖励
8. `LEARNING_RATE` - 微调收敛速度
9. `BATCH_SIZE` - 微调训练稳定性

---

## 监控指标目标值

| 指标 | 目标值 | 可接受范围 | 警告值 |
|------|--------|-----------|--------|
| Completion Rate | > 90% | 85%-95% | < 80% |
| Average Waiting Time | < 150s | 100-200s | > 250s |
| Match Rate | > 92% | 90%-98% | < 85% |
| Cancel Rate | < 8% | 5%-10% | > 15% |
| Loss | < 0.01 | 0.001-0.05 | > 0.1 |
| Epsilon | 0.1 | 0.08-0.15 | - |

---

## 调整模板

复制以下模板进行调整:

```python
# config.py

# 步骤 1: 备份原始值
# ORIGINAL_REWARD_WEIGHTS = {...}

# 步骤 2: 进行调整
REWARD_WEIGHTS = {
    'W_MATCH': 1.2,         # TODO: 调整此值
    'W_WAIT': 1.8,          # TODO: 调整此值
    'W_CANCEL': 1.0,        # TODO: 调整此值
    'W_WAIT_SCORE': 0.4,    # TODO: 调整此值
    'W_COMPLETION': 2.0,    # TODO: 调整此值
    'W_MATCH_SPEED': 0.5    # TODO: 调整此值
}

REWARD_FORMULA_V4 = {
    'T_CHARACTERISTIC': 240.0  # TODO: 调整此值
}

# 步骤 3: 训练并测试
# python -m models.train

# 步骤 4: 查看结果
# python plot_training_curves.py

# 步骤 5: 记录调整结果
# 在此记录调整前后的指标变化
```

---

**提示**: 每次调整后，建议训练至少 5-10 个 Episode 再评估效果，因为前期可能有波动。

